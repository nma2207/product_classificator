{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy2\n",
    "nltk.download('punkt')\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/operator3/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/operator3/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "source": [
    "df = pd.read_excel('profsa/Реестр 327 тыс. деклараций ЕП РФ без 140000-200000.xlsx', sheet_name='все ДС с кодами')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "source": [
    "df_category = pd.read_excel('profsa/Реестр 327 тыс. деклараций ЕП РФ без 140000-200000.xlsx', sheet_name='Список разделов из ЕП РФ (коды)')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "source": [
    "df_category"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Раздел ЕП РФ (Код из ФГИС ФСА для подкатегории продукции)  \\\n",
       "0                                              9300.10           \n",
       "1                                              2364.10           \n",
       "2                                              3482.20           \n",
       "3                                              5990.10           \n",
       "4                                              5970.10           \n",
       "..                                                 ...           \n",
       "398                                            9386.00           \n",
       "399                                            5460.00           \n",
       "400                                            3185.36           \n",
       "401                                            3457.00           \n",
       "402                                            9431.00           \n",
       "\n",
       "                                Подкатегория продукции  Количество ДС по коду  \n",
       "0    Лекарственные средства, зарегистрированные в у...                 207841  \n",
       "1                                   Смеси строительные                  12107  \n",
       "2    Аккумуляторы и аккумуляторные батареи никель-м...                   5059  \n",
       "3    Посуда керамическая (фарфоровая, полуфарфорова...                   4152  \n",
       "4                        Посуда из стекла для взрослых                   3999  \n",
       "..                                                 ...                    ...  \n",
       "398  Бактериофаги (включая бактериофаги для ветерин...                      1  \n",
       "399  Тетради школьные ученические, обои и товары бу...                      1  \n",
       "400  Статические преобразователи для устройств элек...                      1  \n",
       "401  Аппаратура, специально спроектированная для эл...                      1  \n",
       "402                       Инструменты механизированные                      1  \n",
       "\n",
       "[403 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Раздел ЕП РФ (Код из ФГИС ФСА для подкатегории продукции)</th>\n",
       "      <th>Подкатегория продукции</th>\n",
       "      <th>Количество ДС по коду</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9300.10</td>\n",
       "      <td>Лекарственные средства, зарегистрированные в у...</td>\n",
       "      <td>207841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2364.10</td>\n",
       "      <td>Смеси строительные</td>\n",
       "      <td>12107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3482.20</td>\n",
       "      <td>Аккумуляторы и аккумуляторные батареи никель-м...</td>\n",
       "      <td>5059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5990.10</td>\n",
       "      <td>Посуда керамическая (фарфоровая, полуфарфорова...</td>\n",
       "      <td>4152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5970.10</td>\n",
       "      <td>Посуда из стекла для взрослых</td>\n",
       "      <td>3999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>9386.00</td>\n",
       "      <td>Бактериофаги (включая бактериофаги для ветерин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>5460.00</td>\n",
       "      <td>Тетради школьные ученические, обои и товары бу...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>3185.36</td>\n",
       "      <td>Статические преобразователи для устройств элек...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>3457.00</td>\n",
       "      <td>Аппаратура, специально спроектированная для эл...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>9431.00</td>\n",
       "      <td>Инструменты механизированные</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>403 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 478
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "source": [
    "all_sents = []\n",
    "for index, row in df.iterrows():\n",
    "    all_sents.append(row['Общее наименование продукции'])\n",
    "    all_sents.append(row['Подкатегория продукции'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "source": [
    "categories = []\n",
    "for index, row in df_category.iterrows():\n",
    "    categories.append(row['Подкатегория продукции'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "source": [
    "def make_sent_good(sent):\n",
    "    \n",
    "    #print(sent)\n",
    "    tokens = word_tokenize(sent, language=\"russian\")\n",
    "    #print(tokens)\n",
    "    filtered_tokens = []\n",
    "    stop_words = stopwords.words(\"russian\")\n",
    "    for token in tokens:\n",
    "        if token not in stop_words and token.isalpha():\n",
    "#            parsed = morph.parse(token)\n",
    "#            filtered_tokens.append(parsed[0].normal_form)\n",
    "            filtered_tokens.append(token.lower())\n",
    "    return filtered_tokens"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "source": [
    "make_sent_good(all_sents[0])\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['посуда', 'керамическая', 'взрослых', 'кружки', 'логотипом', 'lipton']"
      ]
     },
     "metadata": {},
     "execution_count": 343
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "source": [
    "dataset = [make_sent_good(sent) for sent in all_sents ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "source": [
    "categories = [make_sent_good(sent) for sent in categories]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import pickle\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "with open('posuda_tokenized.pickle', 'wb') as f:\n",
    "    pickle.dump(dataset, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "with open('categories_tokenized.pickle', 'wb') as f:\n",
    "    pickle.dump(categories, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "len(categories)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "source": [
    "w2v_model = Word2Vec(dataset, min_count=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "source": [
    "#https://medium.com/@bigdataschool/%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5-nlp-%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8-word2ve%D1%81-%D0%BD%D0%B0-%D1%80%D1%83%D1%81%D1%81%D0%BA%D0%B8%D1%85-%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B0%D1%85-%D1%81-python-aa10528b99c1\n",
    "w2v_model.train(dataset,total_examples=w2v_model.corpus_count, epochs=500)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(123213875, 177715000)"
      ]
     },
     "metadata": {},
     "execution_count": 365
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "\n",
    "dct = Dictionary(dataset)  # fit dictionary\n",
    "corpus = [dct.doc2bow(line) for line in dataset]  # convert corpus to BoW format\n",
    "tfidf_model = TfidfModel(corpus)  # fit model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "tfidf_model[dct.doc2bow(['алюминевый','посуда'])]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(5, 0.010872943835771207), (1391, 0.999940887799046)]"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "source": [
    "dct.doc2bow(['алюминевый','посуда'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(5, 1), (1815, 1)]"
      ]
     },
     "metadata": {},
     "execution_count": 367
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "w2v_model.wv.get_vector('алюмин').shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "type(w2v_model.wv.get_vector('алюминь'))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"Key 'алюминь' not present\"",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-d34c50156399>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'алюминь'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \"\"\"\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'алюминь' not present\""
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "morph.parse('алюминь')[0].normal_form"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'алюминь'"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "source": [
    "def get_sent_vector(sent):\n",
    "    return d2v_model.infer_vector(sent)\n",
    "    words_vec = [w2v_model.wv.get_vector(word) for word in sent]\n",
    "    res = np.zeros(words_vec[0].shape)\n",
    "    tf_idf_res = tfidf_model[dct.doc2bow(sent)]\n",
    "    for word_vec,  tfidf_coef in zip(words_vec, tf_idf_res):\n",
    "\n",
    "        res += tfidf_coef[1] * word_vec\n",
    "    res /= words_vec[0].shape[0]\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "source": [
    "get_sent_vector(dataset[0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 0.02781032,  0.4085047 , -0.44702992,  0.0539773 , -0.04310822,\n",
       "        0.17545351, -0.13320844, -0.3056218 ,  0.34841716,  0.19193138,\n",
       "        0.15564863, -0.06491449,  0.04263204, -0.20311144, -0.01146553,\n",
       "       -0.11866992,  0.01041583, -0.2678282 ,  0.1257502 ,  0.15241073,\n",
       "       -0.04545007,  0.24235094, -0.08934365,  0.19774266,  0.02240207,\n",
       "        0.04041701,  0.11465981, -0.15462114,  0.01058418,  0.00385917,\n",
       "       -0.22416271, -0.04272363, -0.311184  ,  0.18536225, -0.13066389,\n",
       "        0.0860125 ,  0.02188387, -0.09474594,  0.11391672, -0.1921134 ,\n",
       "        0.09151542, -0.2922439 , -0.25543404,  0.25732645,  0.27427024,\n",
       "        0.1620725 , -0.10673653,  0.01912489,  0.38331243,  0.02361956,\n",
       "        0.44966185, -0.39357105, -0.15504345, -0.21297616, -0.14395915,\n",
       "        0.0376996 , -0.16237636, -0.14683363, -0.15797293, -0.10006488,\n",
       "        0.2838262 ,  0.11812484,  0.07483999,  0.0791963 , -0.15667215,\n",
       "       -0.3462194 , -0.08015029, -0.19231793,  0.04470037, -0.10106123,\n",
       "        0.05302395, -0.17927724, -0.43056488, -0.11890396, -0.15696645,\n",
       "       -0.0358072 , -0.21541192, -0.19190271,  0.1367672 ,  0.1279421 ,\n",
       "        0.2057    , -0.42356664, -0.21702647,  0.03300112,  0.13670942,\n",
       "       -0.02922867, -0.16962206,  0.24276881,  0.1575047 ,  0.04382118,\n",
       "       -0.22187921,  0.0628908 , -0.11547217,  0.08432853,  0.06748521,\n",
       "        0.02782161,  0.04114667, -0.10476915, -0.17018579, -0.18049541],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 397
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "source": [
    "categories_vec = [get_sent_vector(sent) for sent in categories]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "source": [
    "len(categories_vec)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "metadata": {},
     "execution_count": 349
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "source": [
    "def get_best(sent):\n",
    "    vec = get_sent_vector(sent)\n",
    "    similarity = []\n",
    "    for i in range(len(categories)):\n",
    "        dot = np.dot(vec, categories_vec[i])\n",
    "        norm_u = np.sqrt(np.sum(vec**2))\n",
    "        norm_v = np.sqrt(np.sum(categories_vec[i]**2))\n",
    "        cosine_similarity = dot / (norm_u* norm_v)\n",
    "        similarity.append(abs(cosine_similarity))\n",
    "    return similarity\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "source": [
    "def get_best2(sent):\n",
    "    vec = get_sent_vector(sent)\n",
    "    similarity = []\n",
    "    for i in range(len(categories)):\n",
    "        u = vec / np.sum(vec)\n",
    "        v = categories_vec[i] / np.sum(categories_vec[i])\n",
    "        cosine_similarity = np.sum((v - u)**2)\n",
    "        similarity.append(cosine_similarity)\n",
    "    return similarity"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "source": [
    "\n",
    "i = 2\n",
    "res = np.array(get_best(dataset[i]))\n",
    "i_min = res.argmin()\n",
    "print(res)\n",
    "print(i_min)\n",
    "print(dataset[i])\n",
    "print(categories[i_min])\n",
    "print(1 - res / np.sum(res))\n",
    "print(res[i_min])\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.65298    0.7470947  0.6189548  0.62036055 0.64599264 0.6603598\n",
      " 0.5746767  0.6406572  0.34420848 0.6673304  0.3918433  0.5928627\n",
      " 0.64368796 0.5425581 ]\n",
      "8\n",
      "['посуда', 'взрослых', 'коррозионностойкой', 'стали']\n",
      "['посуда', 'керамическая', 'фарфоровая', 'полуфарфоровая', 'фаянсовая', 'майоликовая', 'взрослых']\n",
      "[0.9217385  0.91045856 0.92581654 0.92564803 0.92257595 0.92085403\n",
      " 0.9311234  0.92321545 0.95874566 0.92001855 0.9530365  0.92894375\n",
      " 0.92285216 0.9349729 ]\n",
      "0.34420848\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "source": [
    "dataset[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Посуда', 'керамическая', 'взрослых', 'кружки', 'логотипом', 'Lipton']"
      ]
     },
     "metadata": {},
     "execution_count": 229
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "source": [
    "dataset[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Посуда',\n",
       " 'керамическая',\n",
       " 'фарфоровая',\n",
       " 'полуфарфоровая',\n",
       " 'фаянсовая',\n",
       " 'майоликовая',\n",
       " 'взрослых']"
      ]
     },
     "metadata": {},
     "execution_count": 194
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "source": [
    "get_best(dataset[2])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.4063737,\n",
       " 0.40637377,\n",
       " 0.2371112,\n",
       " 0.2371112,\n",
       " 0.15085855,\n",
       " 0.40637377,\n",
       " 0.32153106,\n",
       " 0.4217005,\n",
       " 0.4063737,\n",
       " 0.09332343,\n",
       " 0.23711118,\n",
       " 0.15085855,\n",
       " 0.35708866,\n",
       " 0.4678715]"
      ]
     },
     "metadata": {},
     "execution_count": 211
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "source": [
    "all_sents[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Посуда керамическая для взрослых:кружки с логотипом \"Lipton\"'"
      ]
     },
     "metadata": {},
     "execution_count": 178
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "source": [
    "all_sents[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Посуда керамическая (фарфоровая, полуфарфоровая, фаянсовая, майоликовая) для взрослых'"
      ]
     },
     "metadata": {},
     "execution_count": 179
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "source": [
    "dataset[2]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Посуда', 'взрослых', 'коррозионностойкой', 'стали']"
      ]
     },
     "metadata": {},
     "execution_count": 180
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "source": [
    "categories[12]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Посуда', 'чугунная', 'черная']"
      ]
     },
     "metadata": {},
     "execution_count": 227
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "source": [
    "dataset[2]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Посуда', 'взрослых', 'коррозионностойкой', 'стали']"
      ]
     },
     "metadata": {},
     "execution_count": 214
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "source": [
    "import fasttext"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "source": [
    "ft = fasttext.load_model('cc.ru.300.bin')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "source": [
    "ft.get_dimension()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "metadata": {},
     "execution_count": 325
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "source": [
    "ft.get_word_vector(dataset[0][0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 0.02499536, -0.02028517, -0.09813499, -0.10727128,  0.10574081,\n",
       "        0.0161325 ,  0.10150688,  0.02346335, -0.00836308, -0.04549556,\n",
       "       -0.08452549,  0.10351308, -0.00691217, -0.07391488, -0.05252884,\n",
       "        0.14316516,  0.09065375, -0.06574064,  0.04293767,  0.02332023,\n",
       "        0.00568039, -0.02961118, -0.00391035,  0.08638075, -0.08155018,\n",
       "        0.07115488, -0.06242096, -0.02066853,  0.03229598,  0.05967253,\n",
       "        0.03437259, -0.10345087, -0.08954046, -0.06979303, -0.05757707,\n",
       "       -0.01896729, -0.06720374, -0.1167922 ,  0.03613598, -0.05500325,\n",
       "        0.06694788,  0.07080831, -0.0037757 ,  0.026268  , -0.00737507,\n",
       "        0.06156323,  0.05973203, -0.10568403,  0.08991084,  0.03073901,\n",
       "        0.03606437, -0.0369144 ,  0.04332462,  0.05498862, -0.04544231,\n",
       "       -0.08502398, -0.01505822, -0.03462733, -0.00989054,  0.06426308,\n",
       "       -0.03130373,  0.03298218,  0.03366033,  0.00819515,  0.01649939,\n",
       "       -0.02235121,  0.00877583,  0.0120823 , -0.01483226, -0.07435109,\n",
       "        0.10125627, -0.0597935 , -0.07773881,  0.09092566, -0.11074116,\n",
       "       -0.03315773, -0.03428057,  0.03968986,  0.02941124, -0.0214663 ,\n",
       "        0.09481894,  0.03677995,  0.00436514, -0.02502464,  0.03058069,\n",
       "        0.01637498,  0.03675243,  0.03544787, -0.10566527,  0.07481503,\n",
       "        0.01323175,  0.03838747,  0.07144963, -0.057372  ,  0.08233454,\n",
       "        0.07563742, -0.06524953, -0.0239933 ,  0.09232378, -0.08575535,\n",
       "       -0.03158661, -0.05031735, -0.02070289,  0.07410814,  0.04460036,\n",
       "        0.06056521,  0.04792541, -0.06979247, -0.11601919,  0.01747381,\n",
       "       -0.0972468 ,  0.08849174,  0.10005715, -0.00275546, -0.08503579,\n",
       "       -0.00815004, -0.01053754,  0.05703238,  0.05850224,  0.06617516,\n",
       "        0.05716038,  0.14180486, -0.04327874, -0.11692099,  0.06413649,\n",
       "       -0.00438086,  0.05750979,  0.02348482,  0.02368284,  0.0965692 ,\n",
       "        0.01900234,  0.01025983, -0.04994918, -0.01138446, -0.08251481,\n",
       "       -0.05057285, -0.01364784, -0.01170528,  0.08892418, -0.07224458,\n",
       "       -0.0110786 ,  0.02964704,  0.02575652, -0.08278298, -0.0538753 ,\n",
       "       -0.00215811, -0.01864123, -0.00308478, -0.00826757, -0.00246077,\n",
       "       -0.05783961, -0.00562087, -0.0775844 ,  0.05310017, -0.02704788,\n",
       "        0.02687579, -0.0264601 , -0.03368327,  0.05953858, -0.0450294 ,\n",
       "        0.01006764,  0.07291567, -0.03137588, -0.01629429, -0.19486606,\n",
       "        0.0749418 , -0.13609968,  0.0209446 ,  0.02148957,  0.08092999,\n",
       "       -0.01759187, -0.0171995 ,  0.11342257, -0.08727502,  0.0503121 ,\n",
       "        0.08518774, -0.01871996,  0.05854616, -0.04782853, -0.0242228 ,\n",
       "        0.0528063 ,  0.02285538,  0.07839452,  0.01317115,  0.0581128 ,\n",
       "        0.05586121, -0.031339  , -0.06571884,  0.01392434, -0.12167986,\n",
       "       -0.05482397, -0.08102357,  0.03374472,  0.02620283, -0.06371784,\n",
       "        0.06366826,  0.0440337 , -0.00645561,  0.04131772,  0.01848072,\n",
       "       -0.10891163,  0.01422261, -0.00313821,  0.01133587,  0.02866909,\n",
       "       -0.00535689,  0.07515087, -0.06352906,  0.01743171,  0.0220313 ,\n",
       "        0.06060648, -0.0331677 ,  0.07345206,  0.05581043, -0.04701923,\n",
       "       -0.03089187,  0.02894946,  0.01113072, -0.02265072, -0.1220625 ,\n",
       "        0.07983552, -0.02620734, -0.04504434, -0.06362762,  0.00859517,\n",
       "        0.01194394,  0.08401503,  0.04854649, -0.08669754, -0.13309436,\n",
       "       -0.09634106,  0.06092934,  0.03250049, -0.01786575,  0.08668935,\n",
       "       -0.03833583,  0.02005929, -0.1286903 , -0.06747983, -0.06448414,\n",
       "       -0.03188307,  0.05760753, -0.00427638, -0.03767478,  0.02640261,\n",
       "       -0.22161143, -0.03185513,  0.01667098,  0.10659056, -0.1137579 ,\n",
       "       -0.08806423,  0.0026679 ,  0.08966649,  0.09036501, -0.03578503,\n",
       "       -0.03532266, -0.00302382, -0.05345177, -0.09901522, -0.08085512,\n",
       "        0.01299754,  0.12524925, -0.07680102,  0.04485855,  0.02756727,\n",
       "        0.07063504, -0.01153994,  0.02825951, -0.08353624, -0.04213421,\n",
       "       -0.06061464, -0.04571998,  0.18454532,  0.10424709, -0.02159913,\n",
       "       -0.04806605, -0.00297128, -0.06140311, -0.02878337,  0.07090726,\n",
       "       -0.08055673, -0.03688264, -0.15868993, -0.05034403, -0.04980489,\n",
       "       -0.05623775, -0.06676408, -0.04045799,  0.03285434,  0.0025145 ,\n",
       "        0.10154605,  0.02786072, -0.05279737, -0.00891766,  0.12651241,\n",
       "       -0.01005687, -0.09070387,  0.0919952 , -0.08348789, -0.02298921],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 331
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "source": [
    "from gensim.models import Doc2Vec"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "source": [
    "d2v_model  = Doc2Vec(dataset)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'words'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-381-a0c6ea107f6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md2v_model\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, documents, corpus_file, vector_size, dm_mean, dm, dbow_words, dm_concat, dm_tag_count, dv, dv_mapfile, comment, trim_rule, callbacks, window, epochs, shrink_windows, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors_lockf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREAL\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 0.0 values suppress word-backprop-updates; 1.0 allows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         super(Doc2Vec, self).__init__(\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus_iterable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcorpus_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_corpus_sanity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             self.train(\n\u001b[1;32m    427\u001b[0m                 \u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, corpus_iterable, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \"\"\"\n\u001b[0;32m--> 878\u001b[0;31m         total_words, corpus_count = self.scan_vocab(\n\u001b[0m\u001b[1;32m    879\u001b[0m             \u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m             \u001b[0mprogress_per\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_per\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mscan_vocab\u001b[0;34m(self, corpus_iterable, corpus_file, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0mcorpus_iterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTaggedLineDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         \u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scan_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_per\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         logger.info(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36m_scan_vocab\u001b[0;34m(self, corpus_iterable, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdocument_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchecked_string_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m                     logger.warning(\n\u001b[1;32m    954\u001b[0m                         \u001b[0;34m\"Each 'words' should be a list of words (usually unicode strings). \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'words'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "source": [
    "documents = []\n",
    "for i, w in enumerate(dataset):\n",
    "    documents.append(gensim.models.doc2vec.TaggedDocument(w, [i]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TaggedDocument(words=['посуда', 'керамическая', 'взрослых', 'кружки', 'логотипом', 'lipton'], tags=[0])"
      ]
     },
     "metadata": {},
     "execution_count": 384
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "source": [
    "d2v_model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=1, dm=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "source": [
    "d2v_model.build_vocab(documents)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "source": [
    "max_epochs = 20\n",
    "vec_size = 20\n",
    "alpha = 0.025\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    d2v_model.train(documents,\n",
    "                total_examples=d2v_model.corpus_count,\n",
    "                epochs=d2v_model.epochs)\n",
    "    # decrease the learning rate\n",
    "    d2v_model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    d2v_model.min_alpha = d2v_model.alpha\n",
    "\n",
    "#model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "Model Saved\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "source": [
    "d2v_model.train(documents)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "You must specify either total_examples or total_words, for proper learning-rate and progress calculations. If you've just built the vocabulary using the same corpus, using the count cached in the model is sufficient: total_examples=model.corpus_count.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-450-e158b49e0316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start_doctags'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_doctags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m         super(Doc2Vec, self).train(\n\u001b[0m\u001b[1;32m    515\u001b[0m             \u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_training_sanity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_corpus_sanity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_check_training_sanity\u001b[0;34m(self, epochs, total_examples, total_words, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_words\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtotal_examples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1536\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1537\u001b[0m                 \u001b[0;34m\"You must specify either total_examples or total_words, for proper learning-rate \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m                 \u001b[0;34m\"and progress calculations. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You must specify either total_examples or total_words, for proper learning-rate and progress calculations. If you've just built the vocabulary using the same corpus, using the count cached in the model is sufficient: total_examples=model.corpus_count."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "source": [
    "d2v_model.wv.get_vector(documents)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-448-1dc2478c14ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \"\"\"\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \"\"\"\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_to_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "source": [
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "#fname = get_tmpfile(\"doc2vec_model.pt\")\n",
    "\n",
    "d2v_model.save(\"doc2vec_model.pt\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "source": [
    "d2v_model.infer_vector(dataset[0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 4.9741031e-04, -1.1396804e-03, -3.6502708e-04,  2.4061282e-04,\n",
       "        1.5370694e-03, -1.3068444e-03, -9.9943276e-04,  2.6318829e-05,\n",
       "        2.0669123e-04, -4.2814514e-04,  1.7092109e-04,  8.0774346e-04,\n",
       "        1.9846737e-04, -1.1614856e-03, -1.3855828e-03, -5.3433614e-04,\n",
       "        7.5544615e-04,  1.7852009e-04,  9.6866809e-04,  1.6451827e-03,\n",
       "        1.2908826e-03,  7.0024031e-04,  4.1137714e-04, -9.1026642e-04,\n",
       "        3.1481424e-04, -1.1642694e-03, -2.7795980e-04, -1.5088087e-03,\n",
       "        3.2496054e-04, -1.1019765e-03,  1.2382535e-03,  9.9714741e-04,\n",
       "       -5.1405816e-04,  1.1994574e-03,  6.5655174e-04, -7.0197490e-04,\n",
       "       -1.2724707e-04,  1.4914417e-03,  2.6703338e-04, -1.0180123e-03,\n",
       "        1.5447185e-03,  2.6629030e-04,  1.1072060e-04,  3.2431126e-04,\n",
       "       -2.0329704e-04, -1.0982716e-03,  8.5493329e-04, -6.3437881e-04,\n",
       "        1.0087359e-03,  2.3080091e-04, -7.3725689e-04, -6.4860506e-04,\n",
       "       -1.6491911e-03,  3.9974053e-05,  1.1195479e-03, -8.2726509e-04,\n",
       "        1.6276230e-03,  1.1490418e-03, -1.3695452e-03,  1.3621481e-03,\n",
       "       -1.3554504e-03, -9.5242658e-04,  1.5102940e-03,  3.0556938e-04,\n",
       "        8.8029302e-04, -1.3543427e-04, -4.3224683e-04,  4.3239296e-04,\n",
       "       -9.6553958e-05,  6.4729236e-04,  1.6203343e-03,  1.4383593e-03,\n",
       "        6.5102120e-04, -1.2558243e-03,  9.3642989e-04,  1.0455906e-04,\n",
       "        8.9358487e-05, -3.8947762e-04, -8.5195102e-04,  3.6391953e-04,\n",
       "        7.6431315e-04,  1.2402451e-03,  1.0190713e-03, -1.4191663e-03,\n",
       "        1.3473646e-03,  3.7469825e-04,  2.1744769e-05,  1.3903680e-03,\n",
       "        4.0598711e-06,  1.5506035e-03,  3.8203996e-04,  4.3106594e-04,\n",
       "        7.2129173e-05,  1.4674653e-03, -1.0403484e-03,  5.6103768e-04,\n",
       "        2.7797520e-04, -1.1255131e-03, -1.4974349e-03, -8.7491580e-04,\n",
       "       -8.7859988e-04, -1.0464052e-04, -7.0269842e-04,  1.3487044e-03,\n",
       "        1.2667918e-03,  3.4274976e-04,  2.7070561e-04, -3.3782364e-04,\n",
       "        1.5638487e-03, -8.5752708e-04,  8.9626512e-05,  6.1684252e-05,\n",
       "       -1.2804506e-03, -1.5487584e-03, -1.0398010e-03,  1.3438646e-03,\n",
       "        3.5465678e-04,  1.6613619e-03,  5.8849930e-04, -7.8647665e-04,\n",
       "        9.7467820e-04, -1.5776505e-04, -1.0618472e-03,  3.6854744e-05,\n",
       "        1.9863744e-04,  1.1821884e-03, -7.9264207e-04, -1.2184137e-03,\n",
       "        1.2643632e-03, -3.9167891e-04,  7.2820007e-04, -7.9520146e-04,\n",
       "        8.5203128e-04,  1.4952809e-03, -1.4066863e-03,  1.5228619e-03,\n",
       "        5.7566067e-04,  9.8483975e-04,  1.5051051e-03,  4.6138585e-04,\n",
       "        1.6055296e-03,  9.0424437e-04, -1.8559645e-04, -1.4640082e-03,\n",
       "       -3.7254463e-04,  1.5669169e-03, -6.9407880e-04, -3.4460635e-04,\n",
       "        1.5971118e-03,  1.4466703e-03, -5.8611861e-04,  5.1481463e-04,\n",
       "        2.8389256e-04,  1.0796074e-03,  3.6274671e-04, -4.8230161e-04,\n",
       "       -1.0022074e-03, -9.5364125e-04, -7.9163723e-04, -1.4396867e-03,\n",
       "        7.1727793e-04, -3.9873223e-05,  1.0775864e-04,  1.2788449e-03,\n",
       "        1.4310479e-05,  9.4456354e-04, -1.1601909e-03,  1.2767877e-03,\n",
       "       -2.0375718e-04,  1.5262672e-03, -1.1736107e-03,  1.3928572e-04,\n",
       "        1.0437107e-03, -7.2312762e-04,  1.2196181e-03,  5.0291675e-04,\n",
       "        8.2262355e-05,  5.6057773e-04, -1.3296289e-03,  1.3464290e-03,\n",
       "        1.1999027e-03, -1.2936377e-03,  1.1859818e-03,  1.2088895e-03,\n",
       "       -6.6777121e-04,  3.5355130e-04,  1.2562879e-03,  1.0130282e-03,\n",
       "       -8.3596409e-05,  1.1985543e-03, -9.1362250e-04,  1.4436956e-03,\n",
       "        1.1584131e-03, -8.2232762e-04,  9.0875366e-04, -3.4364272e-04,\n",
       "        1.6599995e-03,  1.2822472e-03, -1.2611736e-03, -8.6291533e-05,\n",
       "        1.3720652e-03,  1.6469511e-03, -9.8141827e-05,  1.3200033e-03,\n",
       "       -2.9220490e-04, -1.6264125e-03,  1.5873777e-03, -2.7675222e-04,\n",
       "        8.9408597e-04,  1.5474431e-03,  1.5599756e-03,  1.2540710e-03,\n",
       "        6.7814888e-04,  1.5906149e-03, -2.4325430e-04, -1.3061446e-03,\n",
       "        1.3182939e-03, -6.7781436e-04,  8.9284818e-04,  5.8543065e-04,\n",
       "       -1.3019682e-04, -1.4426602e-03,  1.5625206e-03,  9.9081453e-04,\n",
       "       -1.1583093e-03,  4.1576644e-04,  3.3972878e-04,  9.4456715e-04,\n",
       "        1.2758801e-03, -1.0567046e-03,  5.8703840e-04,  1.0943413e-03,\n",
       "        3.2738049e-04, -1.6578906e-03,  1.9197683e-04, -4.2598415e-04,\n",
       "       -1.0302120e-03, -1.0280063e-03,  4.9921713e-04,  1.6366539e-03,\n",
       "       -3.5633464e-04,  1.6998927e-04, -4.8846693e-04,  8.7290088e-04,\n",
       "        5.0354301e-04, -1.2685457e-04,  1.6221367e-03, -1.0515680e-03,\n",
       "       -9.9726580e-04, -1.6600518e-03, -1.0157874e-03,  8.8755885e-05,\n",
       "        5.7399372e-04,  3.0486326e-04, -8.3602668e-04,  1.4534806e-03,\n",
       "       -2.8622925e-04,  1.4158302e-03,  1.1540266e-03, -1.6618792e-03,\n",
       "       -8.4157271e-04, -1.5101185e-03, -1.3960210e-03,  5.0826510e-04,\n",
       "       -4.9002259e-04, -2.5579054e-04, -1.2174939e-03,  3.0380965e-04,\n",
       "        4.1305603e-04,  1.9335350e-05,  9.6049171e-04,  5.4063497e-04,\n",
       "        4.4911346e-04,  5.5814127e-04,  1.2423284e-03, -8.1106415e-04,\n",
       "        1.1053752e-03,  2.6499946e-04, -8.8678102e-04,  1.4325283e-03,\n",
       "       -3.4623058e-04,  9.5415913e-04,  8.7032554e-04, -4.1941216e-04,\n",
       "        5.8150868e-04,  4.7911901e-04,  1.2205410e-03, -6.6937902e-04,\n",
       "       -6.1547739e-04,  1.1879766e-03,  1.2874142e-03,  3.8363616e-04,\n",
       "        1.2605347e-03,  1.6513470e-03, -2.3669381e-04,  1.2542498e-03,\n",
       "       -3.9620351e-04, -1.4694935e-03,  1.0870326e-03, -1.5217903e-03],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 449
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "c493978c77eeaf4df27bbb4b549f9d9ac2c1b872ee758e4e7fcaaa7a681616b7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}